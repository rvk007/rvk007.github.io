(this.webpackJsonpportfolio=this.webpackJsonpportfolio||[]).push([[0],{13:function(e,t,c){},29:function(e,t,c){"use strict";c.r(t);c(1);var s=c(15),n=c.n(s),i=c(2),r=c(4),a=Object(r.a)({basename:""}),o=(c(22),c.p+"static/media/2.36458103.png"),l=c.p+"static/media/gmail.456e473a.svg",d=c.p+"static/media/cv.52ba1127.png",h="data:image/png;base64,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",j=c(0),b=function(){return Object(j.jsx)("div",{className:"container",children:Object(j.jsx)("div",{class:"mt-5",children:Object(j.jsxs)("div",{class:"row",children:[Object(j.jsxs)("div",{class:"col-4 about",style:{textAlign:"center"},children:[Object(j.jsx)("img",{src:o,height:"270vh",width:"270vh",class:"rounded-circle",alt:"photo"}),Object(j.jsx)("h2",{class:"mt-3",children:"Rakhee"}),Object(j.jsx)("h3",{class:"mt-3",style:{fontSize:"2vh"},children:"CS Grad Student"}),Object(j.jsx)("a",{href:"https://www.nyu.edu/",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("h3",{class:"university",style:{fontSize:"2.2vh",color:"orange"},children:"New York University"})}),Object(j.jsxs)("div",{class:"mt-2",children:[Object(j.jsx)("a",{href:"https://github.com/rvk007",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{src:"https://raw.githubusercontent.com/devicons/devicon/9f4f5cdb393299a81125eb5127929ea7bfe42889/icons/github/github-original.svg",width:"25vh",class:"rounded icon",style:{backgroundColor:"whitesmoke"},alt:"github"})}),Object(j.jsx)("a",{href:"https://www.linkedin.com/in/rvk007/",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{src:"https://raw.githubusercontent.com/devicons/devicon/9f4f5cdb393299a81125eb5127929ea7bfe42889/icons/linkedin/linkedin-original.svg",width:"25vh",class:"ml-4 icon",alt:"linkedin"})}),Object(j.jsx)("a",{href:"mailto:rakhee@nyu.edu",children:Object(j.jsx)("img",{src:l,width:"35vh",height:"35vh",class:"ml-4 icon",alt:"gmail"})}),Object(j.jsx)("a",{href:"https://twitter.com/vsharma_rakhee",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{src:"https://raw.githubusercontent.com/devicons/devicon/9f4f5cdb393299a81125eb5127929ea7bfe42889/icons/twitter/twitter-original.svg",width:"25vh",class:"ml-4 icon",alt:"twitter"})}),Object(j.jsx)("a",{href:"https://www.instagram.com/rakhee_1.0/",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{src:"https://www.vectorlogo.zone/logos/instagram/instagram-icon.svg",width:"25vh",class:"ml-4 icon",alt:"instagram"})}),Object(j.jsx)("a",{href:"https://www.facebook.com/rakhee.vishwakarma.3",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{src:"https://raw.githubusercontent.com/devicons/devicon/9f4f5cdb393299a81125eb5127929ea7bfe42889/icons/facebook/facebook-original.svg",width:"25vh",class:"ml-4 icon",alt:"facebook"})}),Object(j.jsx)("a",{href:"https://drive.google.com/file/d/1m4vhwxlrJQT9SeMgglLd7udAgmfqgbhO/view?usp=sharing",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{src:d,style:{backgroundColor:"whitesmoke"},width:"25vh",class:"ml-4 rounded icon",alt:"gmail"})})]})]}),Object(j.jsxs)("div",{class:"col-8",children:[Object(j.jsx)("h1",{class:"experience",children:"Biography"}),Object(j.jsxs)("p",{children:["I am a Master\u2019s student in the Department of Computer Science at the New York University graduating in May 2023. I have a Bachelor of Technology degree in Computer Science and Engineering from the National Institute of Technology (NIT) Mizoram."," "]}),Object(j.jsx)("p",{children:"Previously, I worked at First American India as a Software Engineer, where I elevated legacy IT infrastructure of the company from in-house servers to AWS and made it more secure by applying encryption over MSMQ and TLS communication for database connections. I led a project called \u201cRequirement Analysis Optimization\u201d, which identifies security requirements from a task at the initial stages using machine learning which reduced the time to complete a task by 30%."}),Object(j.jsx)("p",{children:"Aside from work, I am also an open-source enthusiast and have created projects in AI. My interests lie in solving problems related to Computer Vision and Deep Learning."}),Object(j.jsxs)("div",{class:"row mt-5",children:[Object(j.jsxs)("div",{class:"col-6",children:[Object(j.jsx)("h5",{style:{color:"orange"},children:"Interests"}),Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:"Artificial Intelligence"}),Object(j.jsx)("li",{children:"Computer Vision"}),Object(j.jsx)("li",{children:"Natural Language Processing"}),Object(j.jsx)("li",{children:"Deep Reinforcement Learning"})]})]}),Object(j.jsxs)("div",{class:"col-6",children:[Object(j.jsx)("h5",{style:{color:"orange"},children:"Education"}),Object(j.jsxs)("ul",{children:[Object(j.jsxs)("div",{class:"row",children:[Object(j.jsx)("div",{children:Object(j.jsx)("img",{src:h,width:"20vh",height:"20vh",class:"rounded icon",alt:"graduation_cap"})}),Object(j.jsxs)("div",{class:"col-11",children:["MS in Computer Science, 2023",Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{fontSize:"1.4vh"},children:"New York University"})]})]}),Object(j.jsxs)("div",{class:"row",children:[Object(j.jsx)("div",{children:Object(j.jsx)("img",{src:h,width:"20vh",height:"20vh",class:"rounded icon",alt:"graduation_cap"})}),Object(j.jsxs)("div",{class:"col-11",children:["BTech in Computer Science, 2019",Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{fontSize:"1.4vh"},children:"National Institute of Technology Mizoram"})]})]})]})]})]})]})]})})})},A=c.p+"static/media/fai_logo.86165e3f.jpeg",g=c.p+"static/media/iitpatna_logo.706b3924.png",m=(c(13),function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("p",{class:"mt-3",style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"line-1 anim-typewriter-experience",children:"WORK EXPERIENCE"}),Object(j.jsx)("hr",{})]}),Object(j.jsxs)("div",{style:{display:"inline-block"},class:"animated animatedFadeInUp fadeInUp",children:[Object(j.jsx)("div",{class:"card shadow mb-4 rounded border border-dark",children:Object(j.jsx)("div",{class:"card-body",children:Object(j.jsxs)("div",{class:"row col-12",children:[Object(j.jsx)("div",{class:"col-sm-6 col-md-3",children:Object(j.jsx)("img",{src:A,height:"180vh",width:"180vh",class:"logo rounded-circle",alt:"fai"})}),Object(j.jsx)("div",{class:"col-6 col-md-9 d-flex align-items-center justify-content-center",children:Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{class:"experience",children:"FIRST AMERICAN INDIA"}),Object(j.jsxs)("p",{style:{color:"orange"},children:["Member Technical Staff",Object(j.jsx)("br",{}),"July 2019-July 2021"]}),Object(j.jsx)("p",{children:"Elevated legacy IT infrastructure of the company from in-house servers to AWS and made it more secure by applying encryption over MSMQ and TLS communication for database connections."})]})})]})})}),Object(j.jsx)("div",{class:"card my-1 shadow mb-4 rounded border border-dark",children:Object(j.jsx)("div",{class:"card-body",children:Object(j.jsxs)("div",{class:"row col-12",children:[Object(j.jsx)("div",{class:"col-sm-6 col-md-3",children:Object(j.jsx)("img",{src:"data:image/png;base64,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",height:"180vh",width:"180vh",class:"logo rounded-circle",alt:"uqam"})}),Object(j.jsx)("div",{class:"col-6 col-md-9 d-flex align-items-center justify-content-center",children:Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{class:"experience",children:"UNIVERSIT\xc9 DU QU\xc9BEC \xc0 MONTR\xc9AL"}),Object(j.jsxs)("p",{style:{color:"orange"},children:["Research Intern",Object(j.jsx)("br",{}),"June 2018 - August 2018"]}),Object(j.jsx)("p",{children:"Created a model to detect and analyze emotions jointly from textual and visual information. The model achieved an accuracy of 88.6% for assigning correct sentiments for text data and 69.02% for image data. The work done was published at the ICMLA Conference."})]})})]})})}),Object(j.jsx)("div",{class:"card my-1 shadow mb-4 rounded border border-dark",children:Object(j.jsx)("div",{class:"card-body",children:Object(j.jsxs)("div",{class:"row col-12",children:[Object(j.jsx)("div",{class:"col-sm-6 col-md-3",children:Object(j.jsx)("img",{src:g,height:"180vh",width:"180vh",class:"logo rounded-circle",alt:"iit_patna"})}),Object(j.jsx)("div",{class:"col-6 col-md-9 d-flex align-items-center justify-content-center",children:Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{class:"experience",children:"INDIAN INSTITUTE OF TECHNOLOGY PATNA"}),Object(j.jsxs)("p",{style:{color:"orange"},children:["Research Intern",Object(j.jsx)("br",{}),"December 2017 - January 2018"]}),Object(j.jsx)("p",{children:"Implemented a system that helps in finding the most important bi-cluster in the gene expression data using the concepts of Self Organizing Maps and Differential Evolutionary Algorithm."})]})})]})})})]})]})}),O=c.p+"static/media/LEGO_Batman.5075946d.gif",x=c.p+"static/media/depth.d3ef14c7.gif",p=c.p+"static/media/tanoshi.112785e5.gif",u=c.p+"static/media/deepnet_white.8d4e4dd7.png",f=c.p+"static/media/advance_cv.a72ffe44.jpeg",v=c.p+"static/media/machine_translation.101550ef.jpeg",w=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("p",{class:"mt-3",style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"line-1 anim-typewriter-projects",children:"WHAT HAS BEEN KEEPING ME OCCUPIED!"}),Object(j.jsx)("hr",{})]}),Object(j.jsxs)("div",{class:"card-deck row mt-1 mx-5 row-cols-1 row-cols-md-2 animated animatedFadeInUp fadeInUp",children:[Object(j.jsx)("a",{href:"/Projects/ObjectDetection",class:"col mb-3",children:Object(j.jsxs)("div",{class:"card shadow mb-3 rounded border border-secondary",style:{width:"30rem"},children:[Object(j.jsx)("img",{src:O,class:"card-img-top",height:"250vh",alt:"object_detection"}),Object(j.jsx)("div",{class:"card-body",style:{textAlign:"center"},children:Object(j.jsx)("h5",{class:"card-title btn btn-outline-primary mt-1",style:{color:"orange"},children:"Object Detection"})})]})}),Object(j.jsx)("a",{href:"/Projects/DepthEstimationSegmentation",class:"col mb-3",children:Object(j.jsxs)("div",{class:"card shadow mb-3 rounded border border-secondary",style:{width:"30rem"},children:[Object(j.jsx)("img",{src:x,class:"card-img-top",height:"250vh",alt:"depth_estimation"}),Object(j.jsx)("div",{class:"card-body",style:{textAlign:"center"},children:Object(j.jsx)("h5",{class:"card-title btn btn-outline-primary mt-1",style:{color:"orange"},children:"Depth Estimation and Segmentation"})})]})}),Object(j.jsx)("a",{href:"/Projects/Tanoshi",class:"col mb-3",children:Object(j.jsxs)("div",{class:"card shadow mb-3 rounded border border-secondary",style:{width:"30rem"},children:[Object(j.jsx)("img",{src:p,class:"card-img-top",height:"250vh",alt:"tanoshi"}),Object(j.jsx)("div",{class:"card-body",style:{textAlign:"center"},children:Object(j.jsx)("h5",{class:"card-title btn btn-outline-primary mt-1",style:{color:"orange"},children:"Tanoshi"})})]})}),Object(j.jsx)("a",{href:"/Projects/AdvancedComputerVision",class:"col mb-3",children:Object(j.jsxs)("div",{class:"card shadow mb-3 rounded border border-secondary",style:{width:"30rem"},children:[Object(j.jsx)("img",{src:f,class:"card-img-top",height:"250vh",alt:"advance_cv"}),Object(j.jsx)("div",{class:"card-body",style:{textAlign:"center"},children:Object(j.jsx)("h5",{class:"card-title btn btn-outline-primary mt-1",style:{color:"orange"},children:"Advanced Computer Vision"})})]})}),Object(j.jsx)("a",{href:"/Projects/DeepNet",class:"col mb-3",children:Object(j.jsxs)("div",{class:"card shadow mb-3 rounded border border-secondary",style:{width:"30rem"},children:[Object(j.jsx)("img",{src:u,class:"card-img-top",height:"250vh",alt:"deepnet"}),Object(j.jsx)("div",{class:"card-body",style:{textAlign:"center"},children:Object(j.jsx)("h5",{class:"card-title btn btn-outline-primary mt-1",style:{color:"orange"},children:"DeepNet"})})]})}),Object(j.jsx)("a",{href:"/Projects/MachineTranslation",class:"col mb-3",children:Object(j.jsxs)("div",{class:"card shadow mb-3 rounded border border-secondary",style:{width:"30rem"},children:[Object(j.jsx)("img",{src:v,class:"card-img-top",height:"250vh",alt:"machine_translation"}),Object(j.jsx)("div",{class:"card-body",style:{textAlign:"center"},children:Object(j.jsx)("h5",{class:"card-title btn btn-outline-primary mt-1",style:{color:"orange"},children:"Machine Translation"})})]})})]})]})},y=c.p+"static/media/paper.627ccf34.jpg",D=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("p",{class:"mt-3",style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"line-1 anim-typewriter-experience",children:"PUBLICATIONS"}),Object(j.jsx)("hr",{})]}),Object(j.jsx)("div",{class:"card shadow mb-4 rounded border border-secondary animated animatedFadeInUp fadeInUp",children:Object(j.jsx)("div",{class:"card-body",children:Object(j.jsxs)("div",{class:"row col-12",children:[Object(j.jsx)("div",{class:"col-sm-6 col-md-3",children:Object(j.jsx)("a",{href:"https://ieeexplore.ieee.org/document/8614265",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{class:"gif rounded",src:y,height:"300vh",alt:"publication"})})}),Object(j.jsx)("div",{class:"col-6 col-md-9 d-flex align-items-center justify-content-center",children:Object(j.jsxs)("div",{children:[Object(j.jsx)("h5",{class:"experience",children:"Multimodal Sentiment Analysis Using Deep Learning"}),Object(j.jsxs)("p",{style:{color:"orange"},children:[Object(j.jsx)("a",{href:"https://www.linkedin.com/in/rvk007/",target:"_blank",rel:"noopener noreferrer",children:"Rakhee"}),", Ngoc Le Tan, Fatiha Sadat",Object(j.jsx)("br",{}),"17th IEEE International Conference on Machine Learning and Applications (ICMLA) ",Object(j.jsx)("br",{}),"Orlando, Florida, USA (2018)"]}),Object(j.jsx)("p",{children:"Since about a decade ago, deep learning has emerged as a powerful machine learning technique and produced state-of-the-art results in many application domains, ranging from computer vision and speech recognition to NLP. Applying deep learning to sentiment analysis has also become very popular recently. In this paper, we propose a comparative study for multimodal sentiment analysis using deep neural networks involving visual recognition and natural language processing. Initially we make different models for the model using text and another for image and see the results on various models and compare them."}),Object(j.jsx)("div",{children:Object(j.jsx)("a",{href:"https://ieeexplore.ieee.org/document/8614265",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("button",{type:"button",class:"btn btn-primary",children:"Paper"})})})]})})]})})})]})},k=c.p+"static/media/mask_helmet.fd7701fd.gif",I=c.p+"static/media/object_detection_batman.6cbf8b5e.png",Q=function(){return Object(j.jsxs)("div",{class:"container",children:[Object(j.jsxs)("div",{style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"mt-2",children:Object(j.jsx)("p",{class:"line-1 sub-heading",children:"OBJECT DETECTION"})}),Object(j.jsx)("hr",{}),Object(j.jsx)("img",{class:"gif rounded",src:O,height:"350vh",alt:"object_detection"}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("a",{href:"https://github.com/rvk007/EVA4/tree/master/S13",target:"_blank",rel:"noopener noreferrer",class:"col mb-4",children:Object(j.jsx)("button",{type:"button",class:"btn btn-light",children:"GitHub"})}),Object(j.jsx)("a",{target:"_blank",rel:"noopener noreferrer",href:"https://www.youtube.com/watch?v=wl-N1aCklsY",children:Object(j.jsx)("button",{type:"button",class:"btn btn-danger",children:"YouTube"})}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsxs)("div",{children:[Object(j.jsxs)("p",{children:["Object detection with Yolo v3 using transfer learning on a class that doesn't belong to COCO dataset. ",Object(j.jsx)("br",{}),"Class selected: LEGO Batman"]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h5",{children:"Parameters and Hyperparameters"}),Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:"Number of images: 500"}),Object(j.jsx)("li",{children:"Batch size: 10"}),Object(j.jsx)("li",{children:"Epochs: 300"})]})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h5",{children:"Dataset Preparation"}),"For using the LEGO Batman dataset, follow the instructions mentioned",Object(j.jsxs)("ul",{children:[Object(j.jsxs)("li",{children:["The dataset can be downloaded from this"," ",Object(j.jsx)("a",{href:"https://drive.google.com/drive/folders/1uxV3Ml93Nb3sNegLYVIpxc-bi_S4iBSQ",target:"_blank",rel:"noopener noreferrer",children:"link"}),"."]}),Object(j.jsx)("li",{children:"Keep the directory structure same as the one present in the link above."}),Object(j.jsx)("li",{children:"If using another dataset: Update the files batman.names, batman.data, batman.shapes and batman.txt accordingly."}),Object(j.jsxs)("li",{children:["You can access the tool used to annotate the dataset from this"," ",Object(j.jsx)("a",{href:"https://github.com/miki998/YoloV3_Annotation_Tool",target:"_blank",rel:"noopener noreferrer",children:"link"}),"."]})]})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h5",{children:"Train Data"}),"Annotating the images:",Object(j.jsxs)("ul",{children:[Object(j.jsxs)("li",{children:["Clone the annotation tool from this"," ",Object(j.jsx)("a",{href:"https://github.com/miki998/YoloV3_Annotation_Tool",target:"_blank",rel:"noopener noreferrer",children:"link"}),"."]}),Object(j.jsx)("li",{children:"Follow the steps mentioned in the README of the tool specified above."}),Object(j.jsx)("li",{children:"Annotate atleast 500 images with the tool."})]}),"Creating dataset directory:",Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:"Place the annotated images in YoloV3/data/train/images folder."}),Object(j.jsx)("li",{children:"Place the labels in YoloV3/data/train/labels folder."})]})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h5",{children:"Test Data"}),Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:"Download a short-duration video containing the class used during training."}),Object(j.jsxs)("li",{children:["Extract frames from the video into the test directory ",Object(j.jsx)("br",{}),Object(j.jsx)("code",{children:"ffmpeg -i video.mp4 data/test/img%3d.jpg"})]}),Object(j.jsxs)("li",{children:["Extract audio from the video (this audio will be required later)"," ",Object(j.jsx)("br",{}),Object(j.jsx)("code",{children:"ffmpeg -i video.mp4 -f mp3 -ab 192000 -vn audio.mp3"})]})]})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{children:"Downloading Pre-Trained Weights"}),"Download the file named `yolov3-spp-ultralytics.pt` from this"," ",Object(j.jsxs)("a",{href:"https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0",target:"_blank",rel:"noopener noreferrer",children:["link"," "]}),"and place it in YoloV3/weights directory."]}),Object(j.jsx)("br",{}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h5",{children:"Inference on a Video"}),Object(j.jsxs)("ul",{children:[Object(j.jsxs)("li",{children:["Combine the images from the YoloV3/output directory to form a video ",Object(j.jsx)("br",{}),Object(j.jsx)("code",{children:"ffmpeg -framerate 24 -i YoloV3/output/img%3d.jpg -r 24 -y out_video.mp4"})]}),Object(j.jsxs)("li",{children:["Combine the audio file extracted earlier with the output video to produce final output ",Object(j.jsx)("br",{}),Object(j.jsx)("code",{children:"ffmpeg -i out_video.mp4 -i audio.mp3 -shortest result.mp4"})]})]})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{children:"Results"}),"After running the algorithm for 300 epochs, the result is pretty amazing!",Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"rounded",src:I,height:"350vh"})})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h3",{children:"Mask and Helmet Detection"}),"As a part of assignment I did mask and helmet detection on images of construction workers using YoloV3. It also gave pretty good results apter 200 epochs.",Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif rounded",src:k,height:"250vh"})})]})]})]})},E=c.p+"static/media/tanoshi_flowchart.aea474de.png",B=c.p+"static/media/image_dataset.064b4e87.png",C=c.p+"static/media/text_dataset.c14104ac.png",N=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("div",{style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"mt-2",children:Object(j.jsx)("p",{class:"line-1 sub-heading",children:"TANOSHI"})}),Object(j.jsx)("hr",{}),Object(j.jsx)("a",{href:"https://tanoshi.herokuapp.com/",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("img",{class:"gif rounded",src:p,height:"500vh",alt:"tanoshi"})}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("a",{href:"https://github.com/rvk007/Tanoshi",target:"_blank",rel:"noopener noreferrer",class:"col mb-4",children:Object(j.jsx)("button",{type:"button",class:"btn btn-light",children:"GitHub"})}),Object(j.jsx)("a",{href:"https://tanoshi.herokuapp.com/",target:"_blank",rel:"noopener noreferrer",class:"col mb-4",children:Object(j.jsx)("button",{type:"button",class:"btn btn-success",children:"Website"})}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsxs)("div",{children:["This is an end-to-end platform where you can upload your own custom dataset, set model parameters and train your own deep learning model without writing any line of code.",Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),"Tanoshi currently provides Image classification and Sentiment Analysis machine learning models. It has a feature to create a custom model by setting model parameters such as:",Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:"Batch size"}),Object(j.jsx)("li",{children:"Optimizer"}),Object(j.jsx)("li",{children:"Learning rate"}),Object(j.jsx)("li",{children:"Number of epochs"}),Object(j.jsx)("li",{children:"Training-Validation ratio"})]}),"After validating the model parameters an input dataset file a user token is created and training starts, which takes around five-ten minutes. Once training is completed the user can use that token to test their model. ",Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsxs)("div",{children:["There are three major components: of this project:",Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:Object(j.jsx)("a",{href:"https://github.com/rvk007/Tanoshi/tree/master/web",target:"_blank",children:"Heroku"})}),Object(j.jsx)("li",{children:Object(j.jsx)("a",{href:"https://github.com/rvk007/Tanoshi/tree/master/web",target:"_blank",children:"EC2 instance"})}),Object(j.jsx)("li",{children:Object(j.jsx)("a",{href:"https://github.com/rvk007/Tanoshi/tree/master/web",target:"_blank",children:"AWS Lambda"})})]}),"[Go to the above links to know more about this project in detail.]",Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),"The below image explains the work of each component and how they are related to each other:",Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif rounded",src:E,height:"500vh",alt:"tanoshi_flowchart"})})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{children:"Image Classification"}),"Image classification, as the name suggests, ia an algorithm which predicts the content of an image. This project provides two different models, Resnet34 and MobileNetV2 which are pretrained on Imagenet dataset, to classify an image. Use the below format while creating the dataset and make sure to zip it before uploading else it won't be accepted. ",Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif rounded",src:B,height:"350vh",alt:"image_dataset"})})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("h4",{children:"Sentiment Analysis"}),"Sentiment Analysis is a type of text classification, where a text is classified as Positive and Negative. Although, in this project Sentiment analysis is trained from scratch so it can be used for any kind text classification. Again, use the below specified format to create your dataset. The file should be a csv file. ",Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif rounded",src:C,height:"350vh",alt:"text_dataset"})})]})]})]})},T=c.p+"static/media/mask_map.951c9528.png",P=c.p+"static/media/masknet.13040d8d.png",H=c.p+"static/media/depthnet.bbeaad7c.png",M=c.p+"static/media/encoder.04fc02e6.png",X=c.p+"static/media/decoder.9816b175.png",q=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("div",{style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"mt-2",children:Object(j.jsx)("p",{class:"line-1 sub-heading",children:"MONOCULAR DEPTH ESTIMATION AND SEGMENTATION"})}),Object(j.jsx)("hr",{}),Object(j.jsx)("img",{class:"gif",src:x,height:"500vh",alt:"depth_estimation_segmentation"}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("a",{href:"https://github.com/rvk007/Monocular-Depth-Estimation",target:"_blank",rel:"noopener noreferrer",class:"col mb-4",children:Object(j.jsx)("button",{type:"button",class:"btn btn-light",children:"GitHub"})}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsxs)("div",{children:["Depth estimation is a computer vision task designed to estimate depth from a 2D image. Depth information is important for autonomous systems to perceive environments and estimate their own state. The depth image includes information about the distance of the objects in the image from the viewpoint, which is usually the camera taking the image.",Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif",src:T,height:"310vh",alt:"mask_map"})}),Object(j.jsx)("br",{}),"In this project I made a DepthNet Architecture which takes background and a background-foreground image as input and produces their corresponding depth mappings and segmentation masks of the forground. The project is divided into two segments focusing on the two different outputs of the model."]}),Object(j.jsx)("br",{}),Object(j.jsxs)("div",{children:[Object(j.jsx)("a",{href:"https://colab.research.google.com/drive/11drXRdxWF1AFUgtp-0ybKsTYfiHCLsFU?usp=sharing",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("h4",{children:"MaskNet"})}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif",src:P,height:"310vh",alt:"masknet"})}),Object(j.jsxs)("ul",{children:[Object(j.jsx)("li",{children:"The motive of this architecture is to produce Segmentation masks of the given image. A image is a matrix for the computer and in this particular image we require only two pixel values, i.e., 0(Black) and 1(White). We know the power of deep learning, it is a machine learning technique that teaches computers to do what comes naturally to humans: learn by example. Deep learning is a key technology behind driverless cars, it is the key to voice control in consumer devices like phones, tablets, TVs, and hands-free speakers. Deep learning is getting lots of attention lately and for good reason. It\u2019s achieving results that were not possible before."}),Object(j.jsx)("li",{children:"So we now know that predicting two different numbers won't be that difficult for a model to learn."}),Object(j.jsx)("li",{children:"Taking this into consideration I created a pretty small fully convolutional network for MaskNet which takes background and a background-foreground image as input and outputs segmentation masks of the forground."})]}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsxs)("div",{children:[Object(j.jsx)("a",{href:"https://colab.research.google.com/drive/1BFIp-rdOjE4C-PcV6Jm_A7F4NuQRIhj_?usp=sharing",target:"_blank",rel:"noopener noreferrer",children:Object(j.jsx)("h4",{children:"Depthnet"})}),Object(j.jsx)("h5",{children:"Architecture"}),Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif",src:H,height:"450vh",alt:"depthnet"})}),"In the architecture bg denotes the background image and bg_fg denotes background-foreground image. DepthNet follows a encoder-decoder model, since we want images as an output, we convolve the images to get the features by encoding and then convolve up, namely UpSample, decoding the image to reach it's initial dimension.",Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif",src:M,height:"310vh",alt:"encoder"})}),"The model is fully convolutional and includes efficient residual up-sampling blocks \u2014 decoder \u2014 that track high-dimensional regression problems. The first section of the network is proprietary for combining the the inputs together by concatenating them. The second part is a sequence of convolutional and interpolate layers that guide the network in learning its upscaling. In the end a final convolution is applied that yeilds the final predictions.",Object(j.jsx)("p",{style:{textAlign:"center"},children:Object(j.jsx)("img",{class:"gif",src:X,height:"310vh",alt:"decoder"})})]})]})},L=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("div",{style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"mt-2",children:Object(j.jsx)("p",{class:"line-1 sub-heading",children:"ADVANCED COMPUTER VISION"})}),Object(j.jsx)("hr",{}),Object(j.jsx)("img",{src:f,class:"rounded",height:"400vh",alt:"advance_computer_vision"}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("a",{href:"https://github.com/rvk007/Advance-Computer-Vision",target:"_blank",rel:"noopener noreferrer",class:"col mb-4",children:Object(j.jsx)("button",{type:"button",class:"btn btn-light",children:"GitHub"})}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsx)("div",{children:"Coming soon!"})]})},R=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("div",{style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"mt-2",children:Object(j.jsx)("p",{class:"line-1 sub-heading",children:"DEEPNET"})}),Object(j.jsx)("hr",{}),Object(j.jsx)("img",{src:u,className:"rounded",width:"1000vh",height:"220vh",alt:"deepnet"}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{}),Object(j.jsx)("a",{href:"https://github.com/rvk007/DeepNet ",target:"_blank",rel:"noopener noreferrer",class:"col mb-4",children:Object(j.jsx)("button",{type:"button",class:"btn btn-light",children:"GitHub"})}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsx)("div",{children:"Deepnet is an open-source library built on PyTorch used for solving problems of Computer vision in Deep Learning."}),Object(j.jsx)("br",{}),Object(j.jsx)("div",{children:"Coming Soon!"})]})},S=function(){return Object(j.jsxs)("div",{className:"container",children:[Object(j.jsxs)("div",{style:{textAlign:"center"},children:[Object(j.jsx)("p",{class:"mt-2",children:Object(j.jsx)("p",{class:"line-1 sub-heading",children:"MACHINE TRANSLATION"})}),Object(j.jsx)("hr",{}),Object(j.jsx)("img",{src:v,class:"rounded",height:"450vh",alt:"machine_translation"}),Object(j.jsx)("br",{}),Object(j.jsx)("br",{})]}),Object(j.jsx)("div",{children:"Coming Soon!"})]})},G=c(7),U=c.p+"static/media/logo.4d310b86.jpeg",V=function(){return Object(j.jsx)("nav",{class:"navbar navbar-expand-lg navbar-light ",children:Object(j.jsxs)("div",{className:"container",children:[Object(j.jsx)(G.a,{class:"navbar-brand",to:"/",children:Object(j.jsx)("img",{class:"App-logo rounded",src:U,alt:"logo"})}),Object(j.jsx)("button",{class:"navbar-toggler",type:"button","data-toggle":"collapse","data-target":"#navbarText","aria-controls":"navbarText","aria-expanded":"false","aria-label":"Toggle navigation",children:Object(j.jsx)("span",{class:"navbar-toggler-icon"})}),Object(j.jsx)("div",{class:"collapse navbar-collapse",id:"navbarText",children:Object(j.jsxs)("ul",{class:"navbar-nav ml-auto",children:[Object(j.jsx)("div",{children:Object(j.jsx)("li",{class:"nav-item",children:Object(j.jsxs)(G.a,{class:"nav-link px-4",to:"/",style:{color:"whitesmoke "},children:["About","/"===window.location.pathname?Object(j.jsx)("hr",{class:"nav-hr"}):null]})})}),Object(j.jsx)("li",{class:"nav-item",children:Object(j.jsxs)(G.a,{to:"/Experience",class:"nav-link px-4",href:"/Experience",style:{color:"whitesmoke "},children:["Experience",window.location.pathname.includes("/Experience")?Object(j.jsx)("hr",{class:"nav-hr"}):null]})}),Object(j.jsx)("li",{class:"nav-item",children:Object(j.jsxs)(G.a,{class:"nav-link px-4",to:"/Projects",style:{color:"whitesmoke "},children:["Projects",window.location.pathname.includes("/Projects")?Object(j.jsx)("hr",{class:"nav-hr"}):null]})}),Object(j.jsx)("li",{class:"nav-item",children:Object(j.jsxs)(G.a,{class:"nav-link px-4",to:"/Publication",style:{color:"whitesmoke "},children:["Publications","/Publication"===window.location.pathname?Object(j.jsx)("hr",{class:"nav-hr"}):null]})}),Object(j.jsx)("li",{class:"nav-item",children:Object(j.jsxs)("a",{class:"nav-link",href:"https://drive.google.com/file/d/1m4vhwxlrJQT9SeMgglLd7udAgmfqgbhO/view?usp=sharing",style:{color:"whitesmoke "},target:"_blank",rel:"noopener noreferrer",children:["Resume","/Resume"===window.location.pathname?Object(j.jsx)("hr",{class:"nav-hr"}):null]})})]})})]})})},Z=function(){return Object(j.jsx)(i.b,{history:a,children:Object(j.jsxs)("div",{children:[Object(j.jsx)(V,{}),Object(j.jsxs)(i.c,{children:[Object(j.jsx)(i.a,{path:"/",exact:!0,component:b}),Object(j.jsx)(i.a,{path:"/Experience",exact:!0,component:m}),Object(j.jsx)(i.a,{path:"/Projects",exact:!0,component:w}),Object(j.jsx)(i.a,{path:"/Publication",exact:!0,component:D}),Object(j.jsx)(i.a,{path:"/Projects/ObjectDetection",exact:!0,component:Q}),Object(j.jsx)(i.a,{path:"/Projects/Tanoshi",exact:!0,component:N}),Object(j.jsx)(i.a,{path:"/Projects/DeepNet",exact:!0,component:R}),Object(j.jsx)(i.a,{path:"/Projects/DepthEstimationSegmentation",exact:!0,component:q}),Object(j.jsx)(i.a,{path:"/Projects/AdvancedComputerVision",exact:!0,component:L}),Object(j.jsx)(i.a,{path:"/Projects/MachineTranslation",exact:!0,component:S})]})]})})};n.a.render(Object(j.jsx)(Z,{}),document.querySelector("#root"))}},[[29,1,2]]]);
//# sourceMappingURL=main.65c26419.chunk.js.map